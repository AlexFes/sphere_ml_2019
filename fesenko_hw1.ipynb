{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 21 октября 2019, 08:30 \n",
    "\n",
    "**Штраф за опоздание:** по 0.5 балла за 24 часа задержки. Через 10 дней домашнее задание сгорает.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "\n",
    "[ML0919, Задание 1] Фамилия Имя.\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -0.5 баллов\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw1.ipynb) -0.5 баллов\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -0.5 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.datasets import fetch_mldata, fetch_20newsgroups\n",
    "\n",
    "from sklearn.neighbors.base import NeighborsBase, KNeighborsMixin, SupervisedIntegerMixin \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задание 1 (1 балл)\n",
    "Реализовать KNN в классе MyKNeighborsClassifier (обязательное условие: точность не ниже sklearn реализации)\n",
    "Разберитесь самостоятельно, какая мера расстояния используется в KNeighborsClassifier дефолтно и реализуйте свой алгоритм именно с этой мерой. Самостоятельно разберитесь, как считается score из KNeighborsClassifier и реализуйте аналог в своём классе. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pycodestyle\n",
    "\n",
    "\n",
    "class MyKNeighborsClassifier(NeighborsBase, KNeighborsMixin,\n",
    "                             SupervisedIntegerMixin, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, n_neighbors, algorithm='brute'):\n",
    "\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.fit_X = np.array(X)\n",
    "        self.target = np.array(y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions = []\n",
    "        self.counts = []\n",
    "\n",
    "        for test in X:\n",
    "            # Get L2 norm\n",
    "            euclidian_distance = [np.linalg.norm(train - test)\n",
    "                                  for train in self.fit_X]\n",
    "\n",
    "            k_nearest_indices = np.argpartition(\n",
    "                euclidian_distance,\n",
    "                range(self.n_neighbors))[:self.n_neighbors]\n",
    "\n",
    "            unique, indices, counts = np.unique(\n",
    "                self.target[k_nearest_indices],\n",
    "                return_index=True,\n",
    "                return_counts=True)\n",
    "\n",
    "            # Get votes for classes (for probability)\n",
    "            counts_dict = {}\n",
    "\n",
    "            for ind in range(len(counts)):\n",
    "                counts_dict[unique[ind]] = counts[ind]\n",
    "\n",
    "            self.counts.append(counts_dict)\n",
    "            predictions.append(self.target[k_nearest_indices]\n",
    "                               [indices[np.argmax(counts)]])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        self.predict(X)\n",
    "        return np.reshape([\n",
    "            counts_dict[ind] / self.n_neighbors\n",
    "            if ind in counts_dict else 0.0\n",
    "            for counts_dict in self.counts for ind in range(3)], (-1, 3))\n",
    "\n",
    "    def score(self, X, y):\n",
    "\n",
    "        # Jaccard score\n",
    "        dif = self.predict(X) - y\n",
    "        return (y.shape[-1]-np.count_nonzero(dif)) / y.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IRIS**\n",
    "\n",
    "В библиотеке scikit-learn есть несколько датасетов из коробки. Один из них [Ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyKNeighborsClassifier(algorithm='brute', n_neighbors=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (0.5 балла)**\n",
    "\n",
    "Давайте попробуем добиться скорости работы на fit, predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 680 µs, sys: 247 µs, total: 927 µs\n",
      "Wall time: 722 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31 µs, sys: 8 µs, total: 39 µs\n",
      "Wall time: 47.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyKNeighborsClassifier(algorithm='brute', n_neighbors=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.96 ms, sys: 1.73 ms, total: 3.68 ms\n",
      "Wall time: 2.52 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 2, 2, 1, 0, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 ms, sys: 4.49 ms, total: 25.1 ms\n",
      "Wall time: 21.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 0, 0, 0, 2, 2, 1, 0, 2, 2, 1, 1]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.59 ms, sys: 1.14 ms, total: 2.73 ms\n",
      "Wall time: 1.75 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.5, 0.5],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.7 ms, sys: 2.31 ms, total: 21 ms\n",
      "Wall time: 19.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 0.5, 0.5],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [1. , 0. , 0. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 0. , 1. ],\n",
       "       [0. , 1. , 0. ],\n",
       "       [0. , 1. , 0. ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 3 (1 балл)\n",
    "Добавьте algorithm='kd_tree' в реализацию KNN (использовать KDTree из sklearn.neighbors). Необходимо добиться скорости работы на fit,  predict и predict_proba сравнимой со sklearn для iris.\n",
    "Для этого используем numpy. Score не должен уступать значению KNN из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time my_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(my_clf.score(X_test, y_test) - clf.score(X_test,y_test))<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (2.5 балла)**\n",
    "\n",
    "Рассмотрим новый датасет 20 newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='train',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newsgroups['data']\n",
    "target = newsgroups['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведите во всех документах все буквы в нижний регистр и замените во всех документах символы, не\n",
    "являющиеся буквами и цифрами, на пробелы. Далее разбейте текста по пробельным символам на токены(термы/слова). Удалите текста, содержащие только пробелы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tok =  #realize here\n",
    "# data_tok should be a list of lists of tokens for each line in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(isinstance(row, (list, tuple)) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "assert all(all(isinstance(tok, str) for tok in row) for row in data_tok), \"please convert each line into a list of tokens (strings)\"\n",
    "is_latin = lambda tok: all('a' <= x.lower() <= 'z' for x in tok)\n",
    "assert all(map(lambda l: not is_latin(l) or l.islower() , map(' '.join, data_tok))), \"please make sure that you lowercase the data and drop spaced texts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте датасет в разреженную матрицу scipy.sparse.csr_matrix, где значение x в позиции (i, j)\n",
    "означает, что в документе i слово j встретилось x раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Так мы получили векторное представление наших текстов. Значит можно приступать к задаче обучения модели*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте разбиение выборки для кросс-валидации на 3 фолдах. Разрешено использовать sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите метод, позволяющий найти оптимальное количество ближайших соседей(дающее максимальный score в среднем на валидации на 3 фолдах).\n",
    "Постройте график зависимости среднего score от количества соседей. Можно рассмотреть число соседей от 1 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как изменится качество на валидации, если:\n",
    "\n",
    "1. Используется косинусная метрика вместо евклидовой.\n",
    "2. К текстам применяется TfIdf преобразование( sklearn.feature_extraction.text.TfidfTransformer)\n",
    "\n",
    "Сравните модели, выберите лучшую."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим  теперь test  часть нашей выборки и преобразуем её аналогично с train частью. Не забудьте, что наборы слов в train и test части могут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='test',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество(score) вашей лучшей модели на test части датасета. Отличается ли оно от кросс-валидации? Попробуйте сделать выводы, почему отличается качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
